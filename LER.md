O nosso trabalho passou por três fases de implementação. 

A primeira abordagem tomadda passou por excutar dois programas diferentes [topic_retriever.py](topic_retriever.py) e [question_answering.py](question_answering.py). O primeiro circula por todoos documentos e usanf o TDIF Model coleciona os 100 documentos mais relevantes para o tópico e depois coloca eles no JSON chamado **"snippet.json"**. Depois executamos o segundo ficheiro usando o ficheiro JSON preparado para a pergunta que o utilzador irá fazer.

A segunda abordagem foi a implementação do ficheiro [similares.py](similares.py) aonde ambas a *Information Retrieval* e a *Question Answering* são executadas todas no mesmo ficheiro. Aqui a recolha de informação é feita através do uso de *queries* para a base de dados em PostrgreSQL criada por nós. Fazemos um *select* para a recolha do id e do resumo de cada documento para depois quais os mais relevante para o tópico introduzido pelo utilizador. Depois acedemos à outra tabela na base de dados para recolher os textos completos de cada documento para usar como contexto para responder à pergunta imposta.

A última abordagem é a nossa implementação final aonde juntamos as partes positivas de cada uma das implementações anteriores. Ou seja também aqui é excluido o uso de *JSONs* para a recolha de informação, tudo é feito a partir da base de dados criada. Neste mesmo ficheiro chamado [programa.ipynb](programa.ipynb) também fazemos tudo o resto necessário para a respsota da pergunta, aqui o contexto é apenas formado pelo texto completo do documento mias apropriado para a pergunta após ele ser selecionado como um dos ficheiros relevantes para o tópico.