{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (2.9.3)\n",
      "Requirement already satisfied: psycopg2==2.9.3 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from psycopg2-binary) (2.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: click in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from click->nltk) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from importlib-metadata->click->nltk) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from importlib-metadata->click->nltk) (4.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: requests in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from importlib-metadata->transformers) (3.11.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\andre\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg2-binary\n",
    "%pip install pandas\n",
    "%pip install nltk\n",
    "%pip install transformers\n",
    "%pip install scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Baixar as stop words da NLTK\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_config = {\n",
    "    'dbname': 'diariorepublica',\n",
    "    'user': 'postgres',\n",
    "    'password': '1597535',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentRetrieval:\n",
    "    def __init__(self, db_config):\n",
    "        self.conn = psycopg2.connect(**db_config)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        self.vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "        self.df = self.load_documents()\n",
    "        self.tfidf_matrix = self.vectorizer.fit_transform(self.df['notes'])\n",
    "\n",
    "    def load_documents(self):\n",
    "        self.cursor.execute(\"SELECT id, notes FROM dreapp_document\")\n",
    "        rows = self.cursor.fetchall()\n",
    "        return pd.DataFrame(rows, columns=['id', 'notes'])\n",
    "\n",
    "    def search(self, query):\n",
    "        query_vec = self.vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_vec, self.tfidf_matrix).flatten()\n",
    "        related_docs_indices = similarities.argsort()[::-1]\n",
    "        return self.df.iloc[related_docs_indices]\n",
    "\n",
    "    def get_full_text(self, document_id):\n",
    "        self.cursor.execute(\"SELECT html_text FROM dreapp_documenttext WHERE document_id=%s\", (document_id,))\n",
    "        result = self.cursor.fetchone()\n",
    "        return result[0] if result else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QASystem:\n",
    "    def __init__(self):\n",
    "        self.qa_model = pipeline(\"question-answering\", model=\"pierreguillou/bert-large-cased-squad-v1.1-portuguese\")\n",
    "\n",
    "    def answer_question(self, question, context):\n",
    "        response = self.qa_model(question=question, context=context)\n",
    "        return response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAProcessor:\n",
    "    def __init__(self, db_config):\n",
    "        self.document_retrieval = DocumentRetrieval(db_config)\n",
    "        self.qa_system = QASystem()\n",
    "\n",
    "    def process_query(self, query, question):\n",
    "        # Retrieve relevant documents\n",
    "        result = self.document_retrieval.search(query)\n",
    "        document_ids = result['id'][:20]  # Get top 10 documents\n",
    "\n",
    "        # Fetch full texts\n",
    "        texts = [(doc_id, self.document_retrieval.get_full_text(doc_id)) for doc_id in document_ids]\n",
    "\n",
    "        # Identify the most relevant document for the question\n",
    "        question_vec = self.document_retrieval.vectorizer.transform([question])\n",
    "        similarities = [\n",
    "            (doc_id, cosine_similarity(question_vec, self.document_retrieval.vectorizer.transform([text])).flatten()[0])\n",
    "            for doc_id, text in texts if text\n",
    "        ]\n",
    "        most_relevant_doc_id, _ = max(similarities, key=lambda x: x[1])\n",
    "        print(f'Most relevant doc ID: {most_relevant_doc_id}')\n",
    "\n",
    "        # Get the full text of the most relevant document\n",
    "        full_text = self.document_retrieval.get_full_text(most_relevant_doc_id)\n",
    "\n",
    "        # Answer the question using the context of the most relevant document\n",
    "        answer = self.qa_system.answer_question(question, full_text)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_processor = QAProcessor(db_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input(\"Introduz um tópico: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = input(\"Introduz uma pergunta sobre esse tópico: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant doc ID: 3101330\n",
      "Lei Geral do Trabalho em Funções Públicas\n"
     ]
    }
   ],
   "source": [
    "answer = qa_processor.process_query(query, question)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
